{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/InstantIR-hf\n",
    "\n",
    "import os, json, requests, random, time\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffusers import DDPMScheduler\n",
    "from schedulers.lcm_single_step_scheduler import LCMSingleStepScheduler\n",
    "from module.ip_adapter.utils import load_adapter_to_pipe\n",
    "from pipelines.sdxl_instantir import InstantIRPipeline\n",
    "\n",
    "def resize_img(input_image, max_side=1024, min_side=768, width=None, height=None, pad_to_max_side=False, mode=Image.BILINEAR, base_pixel_number=64):\n",
    "    w, h = input_image.size\n",
    "    if width > 0 and height > 0:\n",
    "        out_w, out_h = width, height\n",
    "    elif width > 0:\n",
    "        out_w = width\n",
    "        out_h = round(h * width / w)\n",
    "    elif height > 0:\n",
    "        out_h = height\n",
    "        out_w = round(w * height / h)\n",
    "    else:\n",
    "        out_w, out_h = w, h\n",
    "    # Resize input to runtime size\n",
    "    w, h = out_w, out_h\n",
    "    if min(w, h) < min_side:\n",
    "        ratio = min_side / min(w, h)\n",
    "        w, h = round(ratio * w), round(ratio * h)\n",
    "    if max(w, h) > max_side:\n",
    "        ratio = max_side / max(w, h)\n",
    "        w, h = round(ratio * w), round(ratio * h)\n",
    "    # Resize to cope with UNet and VAE operations\n",
    "    w_resize_new = (w // base_pixel_number) * base_pixel_number\n",
    "    h_resize_new = (h // base_pixel_number) * base_pixel_number\n",
    "    input_image = input_image.resize([w_resize_new, h_resize_new], mode)\n",
    "\n",
    "    if pad_to_max_side:\n",
    "        res = np.ones([max_side, max_side, 3], dtype=np.uint8) * 255\n",
    "        offset_x = (max_side - w_resize_new) // 2\n",
    "        offset_y = (max_side - h_resize_new) // 2\n",
    "        res[offset_y:offset_y+h_resize_new, offset_x:offset_x+w_resize_new] = np.array(input_image)\n",
    "        input_image = Image.fromarray(res)\n",
    "    return input_image, (out_w, out_h)\n",
    "\n",
    "device = \"cuda\"\n",
    "sdxl_repo_id = \"/content/sd_xl_base_1.0\"\n",
    "dinov2_repo_id = \"/content/ComfyUI/models/dinov2\"\n",
    "lcm_repo_id = \"/content/ComfyUI/models/loras/sdxl/lcm\"\n",
    "PROMPT = \"Photorealistic, highly detailed, hyper detailed photo - realistic maximum detail, 32k, \\\n",
    "ultra HD, extreme meticulous detailing, skin pore detailing, \\\n",
    "hyper sharpness, perfect without deformations, \\\n",
    "taken using a Canon EOS R camera, Cinematic, High Contrast, Color Grading. \"\n",
    "NEG_PROMPT = \"blurry, out of focus, unclear, depth of field, over-smooth, \\\n",
    "sketch, oil painting, cartoon, CG Style, 3D render, unreal engine, \\\n",
    "dirty, messy, worst quality, low quality, frames, painting, illustration, drawing, art, \\\n",
    "watermark, signature, jpeg artifacts, deformed, lowres\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    torch_dtype = torch.bfloat16\n",
    "    pipe = InstantIRPipeline.from_pretrained(sdxl_repo_id, torch_dtype=torch_dtype)\n",
    "    load_adapter_to_pipe(pipe, \"/content/ComfyUI/models/InstantIR/models/adapter.pt\", dinov2_repo_id)\n",
    "    lora_alpha = pipe.prepare_previewers(\"/content/ComfyUI/models/InstantIR/models\")\n",
    "    lora_alpha = pipe.prepare_previewers(lcm_repo_id, use_lcm=True)\n",
    "    pipe.to(device=device, dtype=torch_dtype)\n",
    "    pipe.scheduler = DDPMScheduler.from_pretrained(sdxl_repo_id, subfolder=\"scheduler\")\n",
    "    lcm_scheduler = LCMSingleStepScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.scheduler = DDPMScheduler.from_pretrained(sdxl_repo_id,subfolder=\"scheduler\")\n",
    "    lcm_scheduler = LCMSingleStepScheduler.from_config(pipe.scheduler.config)\n",
    "    aggregator_state_dict = torch.load(\"/content/ComfyUI/models/InstantIR/models/aggregator.pt\",map_location=\"cpu\")\n",
    "    pipe.aggregator.load_state_dict(aggregator_state_dict)\n",
    "    pipe.aggregator.to(device=device, dtype=torch_dtype)\n",
    "\n",
    "def instantir_restore(lq, prompt=\"\", negative_prompt=\"\", steps=30, cfg_scale=7.0, guidance_end=1.0, creative_restoration=False, seed=3407, height=None, width=None, preview_start=0.0):\n",
    "    if creative_restoration:\n",
    "        if \"lcm\" not in pipe.unet.active_adapters():\n",
    "            pipe.unet.set_adapter('lcm')\n",
    "    else:\n",
    "        if \"previewer\" not in pipe.unet.active_adapters():\n",
    "            pipe.unet.set_adapter('previewer')\n",
    "\n",
    "    if isinstance(guidance_end, int):\n",
    "        guidance_end = guidance_end / steps\n",
    "    elif guidance_end > 1.0:\n",
    "        guidance_end = guidance_end / steps\n",
    "    if isinstance(preview_start, int):\n",
    "        preview_start = preview_start / steps\n",
    "    elif preview_start > 1.0:\n",
    "        preview_start = preview_start / steps\n",
    "\n",
    "    lq, out_size = resize_img(lq, width=width, height=height)\n",
    "    lq = [lq]\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    timesteps = [i * (1000//steps) + pipe.scheduler.config.steps_offset for i in range(0, steps)]\n",
    "    timesteps = timesteps[::-1]\n",
    "\n",
    "    prompt = PROMPT if len(prompt)==0 else prompt\n",
    "    neg_prompt = NEG_PROMPT if len(negative_prompt)==0 else negative_prompt\n",
    "\n",
    "    out = pipe(\n",
    "        prompt=[prompt]*len(lq),\n",
    "        image=lq,\n",
    "        num_inference_steps=steps,\n",
    "        generator=generator,\n",
    "        timesteps=timesteps,\n",
    "        negative_prompt=[neg_prompt]*len(lq),\n",
    "        guidance_scale=cfg_scale,\n",
    "        control_guidance_end=guidance_end,\n",
    "        preview_start=preview_start,\n",
    "        previewer_scheduler=lcm_scheduler,\n",
    "        return_dict=False,\n",
    "        save_preview_row=False,\n",
    "    )\n",
    "    out[0][0] = out[0][0].resize([out_size[0], out_size[1]], Image.BILINEAR)\n",
    "    return out[0][0]\n",
    "\n",
    "def download_file(url, save_dir, file_name):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    file_suffix = os.path.splitext(urlsplit(url).path)[1]\n",
    "    file_name_with_suffix = file_name + file_suffix\n",
    "    file_path = os.path.join(save_dir, file_name_with_suffix)\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    return file_path\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(input):\n",
    "    values = input[\"input\"]\n",
    "\n",
    "    input_image=values['input_image_check']\n",
    "    input_image=download_file(url=input_image, save_dir='/content/ComfyUI/input', file_name='input_image')\n",
    "    prompt = values['prompt']\n",
    "    negative_prompt = values['negative_prompt']\n",
    "    seed = values['seed']\n",
    "    steps = values['steps']\n",
    "    cfg = values['cfg']\n",
    "    creative_restoration = values['creative_restoration']\n",
    "\n",
    "    if seed == 0:\n",
    "        random.seed(int(time.time()))\n",
    "        seed = random.randint(0, 18446744073709551615)\n",
    "\n",
    "    input_image = Image.open(input_image)\n",
    "    lq_img = resize_img(input_image, max_side=1024, min_side=768, width=0, height=0, pad_to_max_side=False, mode=Image.BILINEAR, base_pixel_number=64)[0]\n",
    "    output_image = instantir_restore(lq_img, prompt=prompt, negative_prompt=negative_prompt, seed=seed, steps=steps, cfg_scale=cfg, creative_restoration=creative_restoration, width=lq_img.size[0],  height=lq_img.size[1])\n",
    "    output_image.save(f\"/content/instantir-{seed}-tost.png\")\n",
    "\n",
    "    result = f\"/content/instantir-{seed}-tost.png\"\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = { \n",
    "    \"input\": {\n",
    "        \"input_image_check\": \"https://files.catbox.moe/syrhel.png\",\n",
    "        \"prompt\": \"Photorealistic, highly detailed, hyper detailed photo - realistic maximum detail, 32k, ultra HD, extreme meticulous detailing, skin pore detailing, hyper sharpness, perfect without deformations, taken using a Canon EOS R camera, Cinematic, High Contrast, Color Grading.\",\n",
    "        \"negative_prompt\": \"blurry, out of focus, unclear, depth of field, over-smooth, sketch, oil painting, cartoon, CG Style, 3D render, unreal engine, dirty, messy, worst quality, low quality, frames, painting, illustration, drawing, art, watermark, signature, jpeg artifacts, deformed, lowres\",\n",
    "        \"seed\": 0,\n",
    "        \"steps\": 20,\n",
    "        \"cfg\": 7.0,\n",
    "        \"creative_restoration\": False,\n",
    "    }\n",
    "}\n",
    "image = generate(input)\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComfyUI-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
